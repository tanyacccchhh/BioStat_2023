---
title: "automatization_notebook_04"
output: word_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(flextable)
library( dplyr)
library(tidyr)
library(scales)
library(ggplot2)
library(reshape2)
library(RColorBrewer)
library(beeswarm)
library(dplyr)
library(gridExtra)
library(broom)



```

# Чтение данных

В вашем варианте нужно использовать датасет healthcare-dataset-stroke-data.

```{r}

data <- read.csv("C:/Users/user/Desktop/задание биостат/healthcare-dataset-stroke-data.csv")


```

# Выведите общее описание данных

```{r}
summary(data)
glimpse(data)


```

# Очистка данных

1) Уберите переменные, в которых пропущенных значений больше 20% или уберите субъектов со слишком большим количеством пропущенных значений. Или совместите оба варианта. Напишите обоснование, почему вы выбрали тот или иной вариант:

**Обоснование**: 

2) Переименуйте переменные в человекочитаемый вид (что делать с пробелами в названиях?);

3) В соответствии с описанием данных приведите переменные к нужному типу (numeric или factor);

4) Отсортируйте данные по возрасту по убыванию;

5) Сохраните в файл outliers.csv субъектов, которые являются выбросами (например, по правилу трёх сигм) — это необязательное задание со звёздочкой;

6) Присвойте получившийся датасет переменной "cleaned_data".

```{r}
# Преобразование переменных к нужному типу и редактирование названий переменных
data <- data |>
  mutate(across(where(is.character) & !bmi, as.factor)) |>
  mutate(across(c(hypertension, heart_disease, stroke), ~factor(recode(.,
    "0" = "No",
    "1" = "Yes")))) |>
  mutate(bmi = as.numeric(if_else(bmi == "N/A", NA, bmi))) |>
  mutate(smoking_status = if_else(smoking_status == "Unknown", NA, smoking_status)) |>
  rename_all(~str_to_title(.)) |>
  rename_all(~str_replace_all(., "_", " ")) |>
  arrange(desc(Age))

# Работа с пропущенными значениями
selected_columns <- data |>
  select(where(~sum(is.na(.))/length(.) > 0.2)) |>
  colnames()

# В переменной smoking_status более 20% пропущенных значений
na_percentage <- sum(is.na(data$SmokingStatus))/nrow(data)

# Очистка данных
cleaned_data <- data |>
  select(where(~sum(is.na(.))/length(.) <= 0.2))

# Работа с выбросами
find_outliers <- function(data, column) {
  data |>
    filter(if_any({{ column }}, ~ . > mean(., na.rm = TRUE) + 3 * sd(., na.rm = TRUE) | . < mean(., na.rm = TRUE) - 3 * sd(., na.rm = TRUE)))
}

outliers <- cleaned_data |>
  find_outliers(where(is.numeric))

write.csv(outliers, "outliers.csv")

cleaned_data <- anti_join(cleaned_data, outliers, by = "Id")
nrow(cleaned_data)

# Удаление пациента с полом "Other"
cleaned_data <- cleaned_data |>
  filter(!Gender == "Other") |>
  mutate(Gender = fct_drop(Gender))




```

# Сколько осталось переменных?

```{r}
num_variables <- ncol(cleaned_data)
cat("Количество оставшихся переменных:", num_variables, "\n")


```

# Сколько осталось случаев?

```{r}

num_cases <- nrow(cleaned_data)
cat("Количество оставшихся случаев:", num_cases, "\n")

```

# Есть ли в данных идентичные строки?

```{r}

# Проверка на наличие идентичных строк
has_duplicate_rows <- any(duplicated(cleaned_data))
if (has_duplicate_rows) {
  cat("В данных есть идентичные строки.\n")
} else {
  cat("В данных нет идентичных строк.\n")
}


```

# Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
# Количество переменных с пропущенными значениями:
data |> 
  select(where(~sum(is.na(.))/length(.) > 0)) |> 
  ncol()

# Количество пропущенных значений в каждой такой переменной:
data |> 
  select(where(~sum(is.na(.))/length(.) > 0)) |>
  summarise(across(everything(), ~sum(is.na(.)), .names = "count_{.col}")) |>
  pivot_longer(cols = everything(), names_to = "variable", values_to = "count")

```

# Описательные статистики

## Количественные переменные

1) Рассчитайте для всех количественных переменных для каждой группы (stroke):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}


data %>%
  select(Stroke, where(is.numeric) & !Id) %>%
  group_by(Stroke) %>%
  summarise(across(where(is.numeric), statistics_num)) %>%
  pivot_longer(!Stroke) %>%
  pivot_wider(names_from = Stroke, values_from = value) %>%
  separate(name, into = c("Переменная", "Статистика"), sep = "_") %>%
  flextable() %>%
  theme_vanilla() %>%
  add_header_row(values = c(" ", "Stroke"), colwidths = c(2, 2)) %>%
  merge_v("Переменная") %>%
  align(align = "center", part = "all") %>%
  set_table_properties(width = 1, layout = "autofit")




```

## Категориальные переменные

1) Рассчитайте для всех категориальных переменных для каждой группы (stroke):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

```{r}
data_cat <- map_dfr(.x = vars(Gender, Hypertension, `Heart disease`, `Ever married`, `Work type`, `Residence type`), .f = statistics_cat)

data_cat |>
  flextable() |>
  theme_vanilla() |>
  add_header_row(values = c(" ", "Stroke"), colwidths = c(3, 2)) |>
  merge_v(c("Переменная", "Категория")) |>
  align(align = "center", part = "all") |>
  set_table_properties(width = 1, layout = "autofit")




```

# Визуализация

## Количественные переменные

1) Для каждой количественной переменной сделайте боксплоты по группам. Расположите их либо на отдельных рисунках, либо на одном, но читаемо;

2) Наложите на боксплоты beeplots - задание со звёздочкой.

3) Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r}



library(ggplot2)
library(ggbeeswarm)
library(RColorBrewer)

graph_num <- function(data, num_var) {
  ggplot(data = data, aes(x = Stroke, y = {{ num_var }})) +
    geom_boxplot(aes(fill = Stroke)) +
    ggbeeswarm::geom_beeswarm(color = "black", size = 0.1, alpha = 0.2) +
    labs(title = rlang::englue("{{ num_var }}")) +
    scale_fill_brewer(palette = "Set2") +
    theme_bw()
}

num_vars <- c("Age", "Avg_glucose_level", "Bmi")

graphs <- lapply(num_vars, function(var) {
  graph_num(cleaned_data, !!as.name(var))
})

graph_num <- function(num_var){
  ggplot(data = cleaned_data, aes(x = Stroke, y = `Avg glucose level`)) +
  geom_boxplot(aes(fill = Stroke)) +
  ggbeeswarm::geom_beeswarm(color = "Black", size = 0.1, alpha = 0.2) +
  labs(title = rlang::englue("{{num_var}}")) +
  scale_fill_brewer(aes(x = Stroke, y = `Avg glucose level`, fill = Stroke), palette="Set2") +
  theme_bw()
}

graph_num_list <- map(.x = vars(Age, `Avg glucose level`, Bmi), .f = graph_num)


for (graph in graph_num_list) {
  print(graph)
}


```

## Категориальные переменные

1) Сделайте подходящие визуализации категориальных переменных. Обоснуйте, почему выбрали именно этот тип.

```{r}


# Функция для визуализации категориальных переменных
graph_cat <- function(data, cat_var) {
  ggplot(data = data, aes(x = {{ cat_var }}, fill = Stroke)) +
    geom_bar(position = "dodge") +
    labs(title = rlang::englue("Распределение переменной {{ cat_var }}"), x = "Категория", y = "Частота") +
    theme_bw()
}

# Список категориальных переменных в вашем наборе данных
cat_vars <- c("Gender", "Hypertension", "Heart disease", "Ever married", "Work type", "Residence type")

# Создание графиков для каждой категориальной переменной
for (cat_var in cat_vars) {
  graph <- graph_cat(cleaned_data, !!as.name(cat_var))
  print(graph)
}


```


# Статистические оценки

## Проверка на нормальность

1) Оцените каждую переменную на соответствие нормальному распределению с помощью теста Шапиро-Уилка. Какие из переменных являются нормальными и как как вы это поняли?

```{r}

# Применение теста Шапиро-Уилка к количественным переменным
shapiro_results <- cleaned_data %>%
  group_by(Stroke) %>%
  select(where(is.numeric) & !Id) %>%
  pivot_longer(cols = -Stroke) %>%
  group_by(Stroke, name) %>%
  summarise(shapiro_p = shapiro.test(value)$p.value) %>%
  arrange(name)

# Вывод результатов
print(shapiro_results)


```

2) Постройте для каждой количественной переменной QQ-плот. Отличаются ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и почему?

```{r}



# Выберем количественные переменные
quantitative_vars <- cleaned_data %>% 
  select(Age, `Avg glucose level`, Bmi)

# Создадим QQ-графики для каждой переменной
qq_plots <- lapply(quantitative_vars, function(var) {
  qq_data <- data.frame(Variable = deparse(substitute(var)), Value = var)
  ggplot(qq_data, aes(sample = Value)) +
    stat_qq() +
    stat_qq_line() +
    labs(title = deparse(substitute(var))) +
    theme_minimal()
})

# Отобразим все QQ-графики на одной странице
grid.arrange(grobs = qq_plots, ncol = 2)


```

3) Ниже напишите, какие ещё методы проверки на нормальность вы знаете и какие у них есть ограничения.

**Тест Колмогорова-Смирнова:

Ограничение по размеру выборки: чувствителен к размеру выборки и может давать ложноположительные результаты при больших выборках.
QQ-графики (квантиль-квантиль графики):

Ограничение по интерпретации: график служит для визуальной оценки и может быть не совсем точным при малых выборках.
Тест Лиллифорса:

Ограничение по размеру выборки: рекомендуется для выборок размером не менее 50 наблюдений.
Ограничение по сложности выборки: неустойчив к выбросам.**


## Сравнение групп

1) Сравните группы (переменная **stroke**) по каждой переменной (как количественной, так и категориальной). Для каждой переменной выберите нужный критерий и кратко обоснуйте его выбор в комментариях.

```{r}
# Wilcoxon тест для количественных переменных
wilcox_test <- function(x, y) {
  wilcox.test(x ~ y) |>
    tidy() |>
    select(method, statistic, `p value` = p.value)
}

# Применение Wilcoxon теста к количественным переменным
cleaned_data  |>
  group_by(Stroke) |> 
  select(where(is.numeric), Stroke) |>
  pivot_longer(cols = -Stroke) |>
  group_by(name) |>
  summarise(wilcox_results = list(wilcox_test(value, Stroke))) |>
  unnest(wilcox_results) |> 
  flextable() |> 
  colformat_double(digits = 3) |> 
  theme_vanilla() |> 
  align(align = "center", part = "all") |>
  set_table_properties(width = 1, layout = "autofit")

# Применение теста Хи-квадрат к категориальным переменным

# По переменной "Work type" объединим редко встречающиеся градации
cleaned_data <- cleaned_data |>
  mutate(`Work type` = recode(`Work type`, "children" = "children_never_worked", "Never_worked" = "children_never_worked"))

# Хи-квадрат тест для категориальных переменных
chisq_test <- function(x, y) {
  chisq.test(x, y) |>
    tidy() |>
    select(method, statistic, `p value` = p.value)
}

# Применение теста Хи-квадрат к категориальным переменным
cleaned_data  |>
  group_by(Stroke) |> 
  select(where(is.factor)) |>
  pivot_longer(cols = -Stroke) |>
  group_by(name) |>
  summarise(chisq_results = list(chisq_test(value, Stroke))) |>
  unnest(chisq_results) |> 
  flextable() |> 
  colformat_double(digits = 3) |> 
  theme_vanilla() |> 
  align(align = "center", part = "all") |>
  set_table_properties(width = 1, layout = "autofit")



```

# Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

## Корреляционный анализ

1) Создайте корреляционную матрицу с визуализацией и поправкой на множественные сравнения. Объясните, когда лучше использовать корреляционные матрицы и в чём минусы и плюсы корреляционных исследований.

```{r}



```

## Моделирование

1) Постройте регрессионную модель для переменной **stroke**. Опишите процесс построения

```{r}



```




